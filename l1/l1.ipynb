{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import editdistance\n",
    "from itertools import chain, permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_shuf.txt', 'r') as stream:\n",
    "    data = stream.readlines()\n",
    "    np.random.shuffle(data)\n",
    "    data = list(map(lambda x: x.split(), data[:10000]))\n",
    "    dictionary = set(list(chain(*data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_match(sentence, dictionary):\n",
    "    start_ind, end_ind = 0, len(sentence)\n",
    "    produced_words = []\n",
    "    while start_ind < end_ind:\n",
    "        if sentence[start_ind:end_ind] in dictionary:\n",
    "            produced_words.append(sentence[start_ind:end_ind])            \n",
    "            start_ind = end_ind\n",
    "            end_ind = len(sentence)\n",
    "        else:\n",
    "            end_ind -= 1\n",
    "    return produced_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_on_two_words(char_list, dictionary):\n",
    "    for i in reversed(range(1, len(char_list))):\n",
    "        if char_list[:i] in dictionary and char_list[i:] in dictionary:\n",
    "            return char_list[:i], char_list[i:]\n",
    "    return None\n",
    "\n",
    "def double_max_match(sentence, dictionary):\n",
    "    start_ind, end_ind = 0, len(sentence)\n",
    "    produced_words = []\n",
    "    while start_ind < end_ind:\n",
    "        splitted_words = split_on_two_words(sentence[start_ind:end_ind], dictionary)\n",
    "        if splitted_words is not None:\n",
    "            produced_words.append(splitted_words[0])            \n",
    "            produced_words.append(splitted_words[1])                        \n",
    "            start_ind = end_ind\n",
    "            end_ind = len(sentence)\n",
    "        else:\n",
    "            end_ind -= 1\n",
    "    return produced_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(sentence1, sentence2):\n",
    "    return editdistance.eval(sentence1, sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean length of sentence: 17.1576\n",
      "Mean distance: 3.0497\n"
     ]
    }
   ],
   "source": [
    "scores = list(map(lambda x: edit_distance(x, max_match(''.join(x), dictionary)), data))\n",
    "print(\"Mean length of sentence: {0}\".format(np.mean(list(map(lambda x: len(x), data)))))\n",
    "print(\"Mean distance: {0}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean length of sentence: 17.1576\n",
      "Mean distance: 2.8856\n"
     ]
    }
   ],
   "source": [
    "scores = list(map(lambda x: edit_distance(x, double_max_match(''.join(x), dictionary)), data))\n",
    "print(\"Mean length of sentence: {0}\".format(np.mean(list(map(lambda x: len(x), data)))))\n",
    "print(\"Mean distance: {0}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_row(row_data):\n",
    "    row_items = row_data.split()\n",
    "    row_items[0] = int(row_items[0])\n",
    "    return row_items\n",
    "\n",
    "def open_ngrams(filename):\n",
    "    with open(filename) as stream:\n",
    "        return list(map(format_row, filter(lambda x: int(x.split()[0]) >= 100, stream.readlines())))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open_ngrams('poleval_2grams.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_successors = {}\n",
    "for _, word1, word2 in data:\n",
    "    if word1 not in word_successors:\n",
    "        word_successors[word1] = set()\n",
    "    word_successors[word1].add(word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kolekcje\n",
      ",\n",
      "aptekach\n",
      ".\n",
      "2b\n",
      "ustawy\n",
      "przyczyni\n",
      "się\n",
      "prowadzi\n",
      "nocny\n",
      ",\n",
      "ubóstwa\n",
      "w\n",
      "wadowicach\n",
      ",\n",
      "kość\n",
      ".\n",
      "?\n",
      "<EOS>\n",
      "bawełna\n",
      ",\n",
      "niewątpliwie\n",
      "będzie\n",
      "decydował\n",
      ",\n",
      "chile\n",
      "i\n",
      "uzależnione\n",
      "jest\n",
      "tendencja\n",
      "do\n",
      "zainstalowania\n",
      "wręczył\n",
      "mu\n",
      "zdobyć\n",
      "się\n",
      "kobieta\n",
      "jest\n",
      "zapowiedź\n",
      ",\n",
      "dzisiejsza\n",
      "dyskusja\n",
      "na\n",
      "sąsiedniej\n",
      "wsi\n",
      "była\n",
      "trochę\n",
      "mało\n",
      "skuteczne\n",
      "i\n",
      "james\n",
      ".\n",
      "4b\n",
      "bangkoku\n",
      ".\n",
      "3a\n",
      "i\n",
      "zaliczył\n",
      "swój\n",
      "język\n",
      "ojczysty\n",
      ".\n",
      "2\n",
      "cm\n",
      "do\n",
      "motocykli\n",
      ".\n",
      "bernardynów\n",
      "w\n",
      "potulicach\n",
      "ustalam\n",
      "czas\n",
      "generowania\n",
      "jednakowa\n",
      "dla\n",
      "zaawansowanych\n",
      ",\n",
      "dużo\n",
      "zależy\n",
      "głównie\n",
      "do\n",
      "18\n",
      "meczów\n",
      "na\n",
      "parkiecie\n",
      ".\n",
      "9\n",
      "000\n",
      "000,00\n",
      "pln\n",
      ",\n",
      "odpowiedź\n",
      ".\n",
      "10\n",
      "armii\n",
      "url\n",
      ".\n",
      "3a\n",
      "pkt\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "current_word = '<BOS>'\n",
    "for i in range(100):\n",
    "    if current_word in word_successors:\n",
    "        current_word = random.choice(list(word_successors[current_word]))\n",
    "    else:\n",
    "        current_word = random.choice(list(word_successors.keys()))\n",
    "    print(current_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open_ngrams('poleval_3grams.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_successors = {}\n",
    "for _, word1, word2, word3 in list(filter(lambda x: len(x) >= 4, data)):\n",
    "    if (word1, word2) not in word_successors:\n",
    "        word_successors[(word1, word2)] = set()\n",
    "    word_successors[(word1, word2)].add(word3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ślub\n",
      "a\n",
      "i\n",
      "w\n",
      "kilku\n",
      "różnych\n",
      "-\n",
      "ryzyku\n",
      "ratuszu\n",
      ",\n",
      "prywatnych\n",
      "tego\n",
      "technicznej\n",
      "rodziny\n",
      "pomiędzy\n",
      "nie\n",
      "ustawy\n",
      "to\n",
      "braki\n",
      "-\n",
      "18\n",
      ",\n",
      "a\n",
      "budowa\n",
      "pól\n",
      "m\n",
      "z\n",
      "przeszkodami\n",
      ".\n",
      "<EOS>\n",
      "calgary\n",
      "tylko\n",
      "gospodarki\n",
      "dla\n",
      "małych\n",
      "przedsiębiorstw\n",
      ",\n",
      "a\n",
      "dotychczasowe\n",
      "gdyby\n",
      "zwrotu\n",
      "z\n",
      "inwestycji\n",
      "w\n",
      "infrastrukturę\n",
      "kolejową\n",
      "kapitał\n",
      "pamiątek\n",
      "w\n",
      "ale\n",
      "wywalczył\n",
      "węgla\n",
      "royal\n",
      "nie\n",
      "przygotowanej\n",
      ",\n",
      "które\n",
      "niosą\n",
      "road\n",
      "mln\n",
      "płynów\n",
      "o\n",
      "regionalny\n",
      "ogólnie\n",
      "spółek\n",
      "spółkami\n",
      "w\n",
      "winogron\n",
      "zakresie\n",
      "produktu\n",
      "nr\n",
      "w\n",
      "działalności\n",
      "na\n",
      "rynku\n",
      ".\n",
      "<EOS>\n",
      "odbierać\n",
      "rat\n",
      "liczby\n",
      "zgłosili\n",
      "jest\n",
      "organizacji\n",
      "black\n",
      "staramy\n",
      "został\n",
      "całym\n",
      "szereg\n",
      "remontów\n",
      "jak\n",
      "dostają\n",
      "że\n",
      ",\n",
      "po\n",
      "studiach\n",
      "w\n",
      "zarządzanych\n",
      "mnie\n",
      "mogą\n",
      "inne\n"
     ]
    }
   ],
   "source": [
    "current_tuple = ('<BOS>', random.choice(list(word_successors.keys()))[0])\n",
    "for i in range(100):\n",
    "    if current_tuple in word_successors:\n",
    "        current_tuple = (current_tuple[1], random.choice(list(word_successors[current_tuple])))\n",
    "    else:\n",
    "        current_tuple = (current_tuple[1], random.choice(list(word_successors.keys()))[0])\n",
    "    print(current_tuple[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open_ngrams('poleval_2grams.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_successors = {}\n",
    "for count, word1, word2 in data:\n",
    "    if word1 not in word_successors:\n",
    "        word_successors[word1] = set()\n",
    "    word_successors[word1].add((word2, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "otóż\n",
      "nie\n",
      "było\n",
      "o\n",
      "świadczeniach\n",
      "rodzinnych\n",
      "w\n",
      "1976\n",
      "r.\n",
      "o\n",
      "udzielanie\n",
      "świadczeń\n",
      ".\n",
      "<EOS>\n",
      "zbytnio\n",
      "od\n",
      "głosu\n",
      "pana\n",
      "prokuratora\n",
      "w\n",
      "tej\n",
      "rzeki\n",
      ".\n",
      "<EOS>\n",
      "336\n",
      ",\n",
      "ale\n",
      "chodzi\n",
      "o\n",
      "0,9\n",
      "%\n",
      "głosów\n",
      ".\n",
      "<EOS>\n",
      "zastrzelony\n",
      "przez\n",
      "samochody\n",
      ".\n",
      "<EOS>\n",
      "dzisiejszych\n",
      "czasach\n",
      "rzymskich\n",
      ".\n",
      "<EOS>\n",
      "mazowieckiego\n",
      "oraz\n",
      "rozszerzenie\n",
      "oferty\n",
      "i\n",
      "tomasz\n",
      "lis\n",
      ",\n",
      "podjąłem\n",
      "decyzję\n",
      "o\n",
      "obowiązku\n",
      "w\n",
      "niektórych\n",
      "innych\n",
      "formach\n",
      ":\n",
      "piotr\n",
      "i\n",
      "zasady\n",
      "dotyczące\n",
      "tego\n",
      ",\n",
      "jest\n",
      "za\n",
      "bardzo\n",
      "duży\n",
      "wysiłek\n",
      "w\n",
      "badaniu\n",
      "klinicznym\n",
      "w\n",
      "1995\n",
      ")\n",
      ".\n",
      "<EOS>\n",
      "post\n",
      ":\n",
      "dla\n",
      "obywateli\n",
      "czy\n",
      "działanie\n",
      "na\n",
      "mistrzostwach\n",
      "polski\n",
      "z\n",
      "obowiązku\n",
      "składania\n",
      "wniosków\n",
      "na\n",
      "prace\n",
      "wykończeniowe\n",
      ",\n",
      "lub\n",
      "nie\n",
      "jest\n"
     ]
    }
   ],
   "source": [
    "current_word = '<BOS>'\n",
    "for i in range(100):\n",
    "    if current_word in word_successors:\n",
    "        successors, counts = zip(*list(word_successors[current_word]))\n",
    "        probabilities = counts / np.sum(counts)\n",
    "        current_word = np.random.choice(successors, p=probabilities)\n",
    "    else:\n",
    "        current_word = random.choice(list(word_successors.keys()))\n",
    "    print(current_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open_ngrams('poleval_3grams.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_successors = {}\n",
    "for count, word1, word2, word3 in list(filter(lambda x: len(x) >= 4, data)):\n",
    "    if (word1, word2) not in word_successors:\n",
    "        word_successors[(word1, word2)] = set()\n",
    "    word_successors[(word1, word2)].add((word3, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miał\n",
      "bez\n",
      ",\n",
      "teraz\n",
      "już\n",
      "nie\n",
      "mówiąc\n",
      "o\n",
      "tym\n",
      "w\n",
      "swoim\n",
      "zakładzie\n",
      "osobą\n",
      "wykorzystania\n",
      "1973\n",
      "ojczyzny\n",
      "35a\n",
      "mieszkańców\n",
      "trójki\n",
      "podkreślić\n",
      "po\n",
      "przez\n",
      "a\n",
      "przegrała\n",
      "wojewódzkiego\n",
      "egzaminu\n",
      "ponad\n",
      "nieruchomości\n",
      "nic\n",
      "wniosek\n",
      "proszę\n",
      "x\n",
      "mamy\n",
      "stan\n",
      "kopenhagi\n",
      "zgłoszone\n",
      "japan\n",
      "1873\n",
      "także\n",
      "kilometr\n",
      "rozłożone\n",
      "reprezentująca\n",
      "pytam\n",
      "przyszłość\n",
      "polskiej\n",
      "nie\n",
      "naftowym\n",
      "ograniczenia\n",
      "zmierzyli\n",
      "co\n",
      "wyjątkiem\n",
      "krwiolecznictwa\n",
      "wstąpił\n",
      "ton\n",
      "kalibru\n",
      "za\n",
      "tych\n",
      ",\n",
      "którzy\n",
      "uważają\n",
      ",\n",
      "że\n",
      "klub\n",
      "parlamentarny\n",
      "sojuszu\n",
      "lewicy\n",
      "demokratycznej\n",
      "nie\n",
      "rok\n",
      "funkcjonowania\n",
      "doktorat\n",
      "w\n",
      "zamka\n",
      "na\n",
      "gazu\n",
      "danego\n",
      "uczy\n",
      "minister\n",
      "obejmuje\n",
      "tym\n",
      "serwisowej\n",
      "odpowiedzialności\n",
      "ulec\n",
      "do\n",
      "politykami\n",
      "według\n",
      "a\n",
      "między\n",
      "małopolskiego\n",
      "wymagających\n",
      "pierwszą\n",
      "zmianie\n",
      "zbyt\n",
      "dystansie\n",
      "grudnia\n",
      "z\n",
      "finansową\n",
      "przetarg\n",
      "leasing\n",
      "września\n"
     ]
    }
   ],
   "source": [
    "current_tuple = ('<BOS>', random.choice(list(word_successors.keys()))[0])\n",
    "for i in range(100):\n",
    "    if current_tuple in word_successors:\n",
    "        successors, counts = zip(*list(word_successors[current_tuple]))\n",
    "        probabilities = counts / np.sum(counts)\n",
    "        current_tuple = (current_tuple[1], np.random.choice(successors, p=probabilities))\n",
    "    else:\n",
    "        current_tuple = (current_tuple[1], random.choice(list(word_successors.keys()))[0])\n",
    "    print(current_tuple[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_predefined(row, predefined_set):\n",
    "    return all([x in predefined_set for x in row.split()[1:]])\n",
    "    \n",
    "def open_predefined_ngrams(filename, predefined_set):\n",
    "    with open(filename) as stream:\n",
    "        return list(map(format_row, filter(lambda x: all_predefined(x, predefined_set), stream.readlines())))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = \"\"\"\n",
    "    Wczoraj wieczorem spotkałem pewną piękną kobietę\n",
    "    Babuleńka miała dwa rogate koziołki\n",
    "    Judyta dała wczoraj Stefanowi czekoladki\n",
    "    Dziś wieczorem jest pracowity dzień\n",
    "    Jutro powinien być luźniejszy dzień \n",
    "    W weekend ugotuję obiad\n",
    "\"\"\"\n",
    "predefined_set = set(\"Wczoraj wieczorem spotkałem pewną piękną kobietę\".split())\n",
    "data = open_predefined_ngrams('poleval_2grams.txt', predefined_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_scores = {(row[1], row[2]): row[0] for row in data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(words):\n",
    "    filtered_tuples = filter(lambda x: x in word_scores, zip(words[:-1], words[1:]))\n",
    "    return sum(map(lambda x: word_scores[x], filtered_tuples))\n",
    "\n",
    "sentence_scores = list(map(lambda x: (get_score(x), x), permutations(predefined_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(68, ('Wczoraj', 'wieczorem', 'spotkałem', 'pewną', 'piękną', 'kobietę')),\n",
       " (68, ('spotkałem', 'pewną', 'piękną', 'kobietę', 'Wczoraj', 'wieczorem')),\n",
       " (68, ('spotkałem', 'pewną', 'piękną', 'kobietę', 'wieczorem', 'Wczoraj')),\n",
       " (68, ('wieczorem', 'Wczoraj', 'spotkałem', 'pewną', 'piękną', 'kobietę')),\n",
       " (68, ('wieczorem', 'spotkałem', 'pewną', 'piękną', 'kobietę', 'Wczoraj'))]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(sentence_scores)[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
